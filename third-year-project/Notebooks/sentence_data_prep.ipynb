{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a979caf7-508d-4c4f-9e0e-56fb5d251095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b943ca7a-1a54-47b9-bc32-282464c7bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text prior to long format\n",
    "original_text = pd.read_hdf(\"C:\\\\Users\\\\tommy\\\\OneDrive\\\\University\\\\Year 3\\\\Third Year Project\\\\Platform Album Data\\\\unigram_data.h5\", key=\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "62fd9fbc-ebd5-4bd2-8602-80f04c816f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the text in long format\n",
    "ordered_text = pd.read_hdf(\"C:\\\\Users\\\\tommy\\\\OneDrive\\\\University\\\\Year 3\\\\Third Year Project\\\\Platform Album Data\\\\new_unigram_data.h5\", key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2cae96be-f720-4c41-a586-6d5574bc9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.nist import NISTTokenizer\n",
    "\n",
    "def replace_quotes(x):\n",
    "    for match in re.findall(\" “.+?[”'\\1{2}]\", x):\n",
    "        x = x.replace(match, \"\")\n",
    "\n",
    "    return x\n",
    "\n",
    "def preprocess(x):\n",
    "    tk = NISTTokenizer()\n",
    "    x = replace_quotes(x)\n",
    "    x = sent_tokenize(x)\n",
    "    x = [[word for word in tk.tokenize(sentence) if word not in string.punctuation] for sentence in x]\n",
    "    \n",
    "    return x\n",
    "\n",
    "platforms = [\"Pitchfork\", \"Guardian\", \"Spectrum\", \"NME\"]\n",
    "\n",
    "# Tokenize by word and sentence, replace quotes and remove punctuation\n",
    "for platform in platforms:\n",
    "    \n",
    "    original_text.loc[:, platform] = original_text.loc[:, platform].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "16b8d599-244c-4983-9b1f-483c00e4ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into long format\n",
    "original_text = original_text.melt(id_vars=[\"Artist\", \"Album\"], value_vars=[\"Pitchfork\", \"Guardian\", \"Spectrum\", \"NME\"], var_name=\"Platform\", value_name=\"Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7de7c3fc-0e93-4840-ae83-160054227afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of nan occurrences from empty splits on tokenization\n",
    "original_text.loc[:, \"Text\"] = original_text.loc[:, \"Text\"].apply(lambda x: [[word for word in sentence if word != np.nan] for sentence in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc6155a7-9f27-4a57-a15f-55ec12c93680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with a weird character so that it can be easily split again without interfering with the data\n",
    "# In hindsight could've just used a whitespace\n",
    "original_text[\"Full Text\"] = original_text.loc[:, \"Text\"].apply(lambda x: \"|\".join([\"|\".join(sent) for sent in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f777d181-519b-4240-924e-f723751cd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of duplicate rows where multiple guardian reviews were present\n",
    "original_text = original_text.drop_duplicates(subset=[\"Full Text\"]).drop(columns=[\"Full Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "96564016-614f-4b72-80d6-79d6f66bcb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tommy\\AppData\\Local\\Temp\\ipykernel_6112\\1346405857.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  original_text.loc[:, \"Artist\"] = pd.Categorical(original_text.loc[:, \"Artist\"], artist_album_sort.loc[:, \"Artist\"].unique())\n",
      "C:\\Users\\tommy\\AppData\\Local\\Temp\\ipykernel_6112\\1346405857.py:5: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  original_text.loc[:, \"Album\"] = pd.Categorical(original_text.loc[:, \"Album\"], artist_album_sort.loc[:, \"Album\"].unique())\n",
      "C:\\Users\\tommy\\AppData\\Local\\Temp\\ipykernel_6112\\1346405857.py:6: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  original_text.loc[:, \"Platform\"] = pd.Categorical(original_text.loc[:, \"Platform\"], [\"Pitchfork\", \"Guardian\", \"Spectrum\", \"NME\"])\n"
     ]
    }
   ],
   "source": [
    "# Sort by the same ordering as the text\n",
    "artist_album_sort = ordered_text.loc[:, [\"Artist\", \"Album\"]]\n",
    "# pd.categorical allows you to sort by the index of ordered_text\n",
    "original_text.loc[:, \"Artist\"] = pd.Categorical(original_text.loc[:, \"Artist\"], artist_album_sort.loc[:, \"Artist\"].unique())\n",
    "original_text.loc[:, \"Album\"] = pd.Categorical(original_text.loc[:, \"Album\"], artist_album_sort.loc[:, \"Album\"].unique())\n",
    "original_text.loc[:, \"Platform\"] = pd.Categorical(original_text.loc[:, \"Platform\"], [\"Pitchfork\", \"Guardian\", \"Spectrum\", \"NME\"])\n",
    "# Use the sorting methods outlined above to sort the entire dataset\n",
    "original_text = original_text.sort_values([\"Platform\", \"Album\", \"Artist\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b3234907-c6b7-4618-8aea-eb63faf5b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text[\"Review id\"] = [x for x in range(original_text.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dfdef0c4-3807-4a4d-a55d-acc6c8b3b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tommy\\AppData\\Local\\Temp\\ipykernel_6112\\3960460241.py:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  ordering.loc[:, \"Artist\"] = pd.Categorical(ordering.loc[:, \"Artist\"], ordered_text.loc[:, \"Artist\"].unique(), True)\n",
      "C:\\Users\\tommy\\AppData\\Local\\Temp\\ipykernel_6112\\3960460241.py:3: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  ordering.loc[:, \"Album\"] = pd.Categorical(ordering.loc[:, \"Album\"], ordered_text.loc[:, \"Album\"].unique(), True)\n",
      "C:\\Users\\tommy\\AppData\\Local\\Temp\\ipykernel_6112\\3960460241.py:4: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  ordering.loc[:, \"Platform\"] = pd.Categorical(ordering.loc[:, \"Platform\"], [\"Pitchfork\", \"Guardian\", \"Spectrum\", \"NME\"], True)\n"
     ]
    }
   ],
   "source": [
    "ordering = ordered_text.copy()\n",
    "ordering.loc[:, \"Artist\"] = pd.Categorical(ordering.loc[:, \"Artist\"], ordered_text.loc[:, \"Artist\"].unique(), True)\n",
    "ordering.loc[:, \"Album\"] = pd.Categorical(ordering.loc[:, \"Album\"], ordered_text.loc[:, \"Album\"].unique(), True)\n",
    "ordering.loc[:, \"Platform\"] = pd.Categorical(ordering.loc[:, \"Platform\"], [\"Pitchfork\", \"Guardian\", \"Spectrum\", \"NME\"], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ac348a50-e50a-4c6b-ab2c-0e6bcff3f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordering = ordering.sort_values(by=[\"Platform\", \"Album\", \"Artist\"])\n",
    "original_text.loc[:, \"Review id\"] = ordering.loc[:, \"Review id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "daffee9c-f2b1-4f5c-b55b-51ba7fe8bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text.loc[:, \"Text\"] = original_text.apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1f7885b7-e8ab-4368-9b24-c258a9c9abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = original_text.astype({\"Artist\": str,\n",
    "                    \"Album\": str,\n",
    "                    \"Platform\": str,\n",
    "                    \"Text\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5c3e8fea-e293-4c83-8a80-9a3544b512e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "original_text.loc[:, \"Text\"] = original_text.loc[:, \"Text\"].apply(\n",
    "    lambda x: str([sentence for sentence in ast.literal_eval(x) if len(sentence) > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "405a672d-d263-41ca-af64-c8dd0c1d7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text.to_hdf(\"C:\\\\Users\\\\tommy\\\\OneDrive\\\\University\\\\Year 3\\\\Third Year Project\\\\Platform Album Data\\\\new_unigram_data.h5\", key=\"sentence\", format=\"table\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
